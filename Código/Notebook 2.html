---
title: "Stacking y comparación de validación cruzada en Random Forest"
author: "Lina Alvarez Ardila - Sara Rocio Rojas"
date: "`r Sys.Date()`"
output: htlm_document
---

## Introducción

En este ejercicio exploramos la robustez y desempeño de modelos Random Forest usando dos esquemas de validación cruzada: **normal (aleatoria)** y **espacial**.  
Debido a limitaciones computacionales asociadas al tamaño de la base, tomamos una muestra representativa para permitir el ajuste eficiente y experimentar con **stacking** y enfoques más avanzados.

---

## Preparación y reducción de la muestra

Reducimos la muestra a 2,000 registros seleccionados aleatoriamente, lo que nos permitió correr los modelos en un entorno de recursos limitados sin perder la representatividad espacial y de características estructurales.  
El preprocesamiento incluyó eliminación de variables irrelevantes y remoción de observaciones incompletas para evitar errores en el ajuste.

```{r setup, message=FALSE, warning=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(readr, caret, randomForest, dplyr, cluster)

# 1. Cargar y preparar datos
train = read_csv("https://www.dropbox.com/scl/fi/pnw43edk4uewsd13g1oxj/train.csv?rlkey=vxuc9vej4ruom9dg0y5b2zh0c&st=1zp7ez1e&dl=1")
cols_to_remove <- c("city", "title", "description","operation_type")
train <- train[ , !(names(train) %in% cols_to_remove)]
train <- na.omit(train)

# 2. Toma una muestra para evitar problemas de memoria (ajusta n según RAM)
set.seed(123)
n_muestra <- 2000
train_small <- train %>% sample_n(n_muestra)
```

##Validación cruzada:

```{r}
rf_control <- trainControl(method = "cv", number = 3, savePredictions = "final")
rf_tunegrid <- expand.grid(mtry = 2)

set.seed(123)
modelo_rf_normal <- train(
  price ~ ., data = train_small,
  method = "rf",
  trControl = rf_control,
  tuneGrid = rf_tunegrid,
  ntree = 10,
  nodesize = 10,
  importance = FALSE
)

cat("\n--- VC Normal (aleatoria) ---\n")
print(modelo_rf_normal$resample$RMSE)
cat("RMSE promedio (VC normal): ", mean(modelo_rf_normal$resample$RMSE), "\n")
rf_control <- trainControl(method = "cv", number = 3, savePredictions = "final")
rf_tunegrid <- expand.grid(mtry = 2)

set.seed(123)
modelo_rf_normal <- train(
  price ~ ., data = train_small,
  method = "rf",
  trControl = rf_control,
  tuneGrid = rf_tunegrid,
  ntree = 10,
  nodesize = 10,
  importance = FALSE
)

cat("\n--- VC Normal (aleatoria) ---\n")
print(modelo_rf_normal$resample$RMSE)
cat("RMSE promedio (VC normal): ", mean(modelo_rf_normal$resample$RMSE), "\n")

```
## Validación cruzada espacial
```{r}
# Clustering K-means según lat/lon
set.seed(123)
coords <- train_small %>% select(lat, lon)
clustering <- kmeans(coords, centers = 3)
train_small$spatial_fold <- clustering$cluster

rf_control_spatial <- trainControl(
  method = "cv",
  number = 3,
  index = lapply(1:3, function(i) which(train_small$spatial_fold != i)),
  indexOut = lapply(1:3, function(i) which(train_small$spatial_fold == i)),
  savePredictions = "final"
)

set.seed(123)
modelo_rf_spatial <- train(
  price ~ . -spatial_fold, data = train_small,
  method = "rf",
  trControl = rf_control_spatial,
  tuneGrid = rf_tunegrid,
  ntree = 10,
  nodesize = 10,
  importance = FALSE
)

cat("\n--- VC Espacial ---\n")
print(modelo_rf_spatial$resample$RMSE)
cat("RMSE promedio (VC espacial): ", mean(modelo_rf_spatial$resample$RMSE), "\n")
```


```{r}
boxplot(modelo_rf_normal$resample$RMSE, modelo_rf_spatial$resample$RMSE,
        names = c("Normal CV", "Spatial CV"),
        ylab = "RMSE", main = "Comparación de validación cruzada")

```

La comparación muestra que el error de predicción en validación cruzada espacial suele ser mayor y más variable que en la validación aleatoria, reflejando la dificultad de predecir precios inmobiliarios en zonas completamente nuevas.
Este resultado evidencia la importancia de incorporar validaciones espaciales en estudios aplicados de Machine Learning con datos georreferenciados, y justifica la reducción de muestra como estrategia válida cuando se desea experimentar con modelos complejos como stacking o Random Forest en contextos de recursos computacionales limitados.











